{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from nc_processing import *\n",
    "from analysis import * \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data directory to search for files using lists\n",
    "ceda_dir='/badc/cmip6/data/CMIP6/{project}/{centre}/{model}/{exp}/{run}/{domain}/{var}/gn/latest/'\n",
    "# define the base of the filename for the output file(s) using lists, note this matches the file format in the data directory except for the date_4_file section and the missing .nc. \n",
    "out_base='{var}_{domain}_{model}_{exp}_{run}_gn_{time_range}' # all that's missing is a .nc but we can add that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean(var,exp,dates,project):\n",
    "    data_dir='/home/users/quigley/Projects/geoengineering_summer' #Changed from Pete's directory\n",
    "    model='UKESM1-0-LL'\n",
    "    centre='MOHC'\n",
    "    \n",
    "    if var == \"evspsblpot\":\n",
    "        domain = \"Emon\"  # source documentation said it used Emon, not Amon, so I gave this a try. Didn't work\n",
    "    else:\n",
    "        domain='Amon' # pr is an Amon variable.\n",
    "    \n",
    "    runs=['r1i1p1f2','r4i1p1f2','r8i1p1f2']\n",
    "    grid='gn'\n",
    "    season='ANN'\n",
    "    time_files=1\n",
    "    \n",
    "    # Use the get_fixed() function to return the gridcell area and land fraction for the model we want.\n",
    "    ds_area, ds_land = get_fixed('MOHC','UKESM1-0-LL','r1i1p1f2') \n",
    "\n",
    "    # Let's define a data array for the area weight of the gridcells\n",
    "    da_weight = ds_area['areacella'] / ds_area['areacella'].sum()\n",
    "    da_weight = da_weight.rename(new_name_or_name_dict='area_weight')\n",
    "\n",
    "    # load the arguments into a list then... \n",
    "    args=[season,dates,data_dir,model,centre,var,domain,exp,project,runs,grid,time_files]\n",
    "    ds_mean, ds_std = get_ens_seasonal_mean_std(*args) # ... unpack them into the function.\n",
    "    \n",
    "    # multiply each temperature value with its corresponding fraction of total area, then sum to find the global mean.\n",
    "    return (ds_mean[var]*da_weight).sum() - 273.15 # convert from K to C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moderated_exacerbated(var):\n",
    "    # Use the get_fixed() function to return the gridcell area and land fraction for the model we want.\n",
    "    ds_area, ds_land = get_fixed('MOHC','UKESM1-0-LL','r1i1p1f2') \n",
    "    # NOTE - to do this for another model, you'll need to look up the run number used in the piControl experiment which stores the fx variables.\n",
    "    # search on CEDA archive for \"areacella\" and \"<MODEL NAME>\" and it should show you.\n",
    "\n",
    "    # Let's define a data array for the area weight of the gridcells\n",
    "    da_weight = ds_area['areacella'] / ds_area['areacella'].sum()\n",
    "    da_weight = da_weight.rename(new_name_or_name_dict='area_weight')\n",
    "    # land area = gricell area * land fraction ([0-100] * 0.01)\n",
    "    da_land_area = ds_area['areacella'] * ds_land['sftlf'] * 0.01 \n",
    "    # Now let's create a land area weighting\n",
    "    da_land_weight = da_land_area / da_land_area.sum()\n",
    "    \n",
    "    data_dir='/home/users/quigley/Projects/geoengineering_summer'\n",
    "\n",
    "    # Set variables that are common to all experiments.\n",
    "    model='UKESM1-0-LL'\n",
    "    centre='MOHC' \n",
    "    \n",
    "    if var == \"evspsblpot\":\n",
    "        domain = \"Emon\"\n",
    "    else:\n",
    "        domain='Amon' # pr is an Amon variable.\n",
    "    grid='gn'\n",
    "    season='ANN'\n",
    "\n",
    "    # specify a list of runs\n",
    "    runs=['r1i1p1f2','r4i1p1f2','r8i1p1f2']\n",
    "\n",
    "    # Load G6sulfur ensemble-mean datasets\n",
    "    exp='G6sulfur'\n",
    "    project='GeoMIP'\n",
    "    dates=['2070-01-01','2100-01-01']\n",
    "    ds_G6sulfur_mean, ds_G6sulfur_std = get_ens_seasonal_mean_std(season, dates, data_dir, model, centre, var, domain, exp, project, runs, grid, time_files=1)# setting time files to zero.\n",
    "\n",
    "    # Load ssp585 ensemble-mean datasets\n",
    "    project='ScenarioMIP'\n",
    "    exp='ssp585'\n",
    "    dates=['2070-01-01','2100-01-01']\n",
    "    ds_ssp585_mean, ds_ssp585_std = get_ens_seasonal_mean_std(season, dates, data_dir, model, centre, var, domain, exp, project, runs, grid, time_files=1)# setting time files to zero.\n",
    "\n",
    "    # Load ssp585 ensemble-mean datasets\n",
    "    project='CMIP'\n",
    "    exp='historical'\n",
    "    dates=['1960-01-01','1990-01-01']\n",
    "    ds_historical_mean, ds_historical_std = get_ens_seasonal_mean_std(season, dates, data_dir, model, centre, var, domain, exp, project, runs, grid, time_files=1)# setting time files to zero.\n",
    "    \n",
    "    # Call my better_worse_off function, passing in the data_arrays for the variable of interest rather than the full datasets.\n",
    "    better, worse, dunno = better_worse_off(ds_G6sulfur_mean[var], ds_G6sulfur_std[var], ds_ssp585_mean[var], ds_ssp585_std[var], ds_historical_mean[var], ds_historical_std[var], 90, 0.05)\n",
    "    \n",
    "    #Calculating the moderated/exacerbated arrays before determining significance\n",
    "    global_moderated = 100.*((better + 0) * da_weight).values\n",
    "    global_exacerbated = 100.*((worse + 0) * da_weight).values\n",
    "    land_moderated = 100.*((better + 0) * da_land_weight).values\n",
    "    land_exacerbated = 100.*((worse + 0) * da_land_weight).values\n",
    "    \n",
    "    return global_moderated, global_exacerbated, land_moderated, land_exacerbated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files pr_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files pr_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files pr_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n"
     ]
    }
   ],
   "source": [
    "global_moderated, global_exacerbated, land_moderated, land_exacerbated = moderated_exacerbated(\"pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.19718435e-05, 6.19718435e-05, 6.19718435e-05, ...,\n",
       "        6.19718435e-05, 6.19718435e-05, 6.19718435e-05],\n",
       "       [1.85886529e-04, 1.85886529e-04, 1.85886529e-04, ...,\n",
       "        1.85886529e-04, 1.85886529e-04, 1.85886529e-04],\n",
       "       [3.09712755e-04, 3.09712755e-04, 3.09712755e-04, ...,\n",
       "        3.09712755e-04, 3.09712755e-04, 3.09712755e-04],\n",
       "       ...,\n",
       "       [3.09712755e-04, 3.09712755e-04, 3.09712755e-04, ...,\n",
       "        3.09712755e-04, 3.09712755e-04, 3.09712755e-04],\n",
       "       [1.85886529e-04, 1.85886529e-04, 1.85886529e-04, ...,\n",
       "        1.85886529e-04, 1.85886529e-04, 1.85886529e-04],\n",
       "       [6.19718435e-05, 6.19718435e-05, 6.19718435e-05, ...,\n",
       "        6.19718435e-05, 6.19718435e-05, 6.19718435e-05]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_moderated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(var,exp,dates,project):\n",
    "    data_dir='/home/users/quigley/Projects/geoengineering_summer' #Changed from Pete's directory\n",
    "    model='UKESM1-0-LL'\n",
    "    centre='MOHC'\n",
    "    \n",
    "    if var == \"evspsblpot\":\n",
    "        domain = \"Emon\"  # source documentation said it used Emon, not Amon, so I gave this a try. Didn't work\n",
    "    else:\n",
    "        domain='Amon' # pr is an Amon variable.\n",
    "    \n",
    "    runs=['r1i1p1f2','r4i1p1f2','r8i1p1f2']\n",
    "    grid='gn'\n",
    "    season='ANN'\n",
    "    time_files=1\n",
    "    \n",
    "    # Use the get_fixed() function to return the gridcell area and land fraction for the model we want.\n",
    "    ds_area, ds_land = get_fixed('MOHC','UKESM1-0-LL','r1i1p1f2') \n",
    "\n",
    "    # Let's define a data array for the area weight of the gridcells\n",
    "    da_weight = ds_area['areacella'] / ds_area['areacella'].sum()\n",
    "    da_weight = da_weight.rename(new_name_or_name_dict='area_weight')\n",
    "\n",
    "    # load the arguments into a list then... \n",
    "    args=[season,dates,data_dir,model,centre,var,domain,exp,project,runs,grid,time_files]\n",
    "    ds_mean, ds_std = get_ens_seasonal_mean_std(*args) # ... unpack them into the function.\n",
    "    \n",
    "    return ds_mean, ds_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n"
     ]
    }
   ],
   "source": [
    "var = \"tas\"\n",
    "exp = \"G6sulfur\"\n",
    "exp2 = \"G6solar\"\n",
    "dates = ['2070-01-01','2100-01-01']\n",
    "project = \"GeoMIP\"\n",
    "\n",
    "ds_mean, ds_std = stats(var, exp, dates, project)\n",
    "\n",
    "ds_mean_2, ds_std_2 = stats(var, exp2, dates, project)\n",
    "\n",
    "num_years = 90 # the t-test needs to know how long our sample is.\n",
    "\n",
    "# ttest_sub returns a numpy array of P-values, where P is between 0 and 1. for 95% significance P is below 0.05\n",
    "ttest_pvalue = ttest_sub(ds_mean[var],ds_std[var],num_years,ds_mean_2[var],ds_std_2[var],num_years)\n",
    "\n",
    "# Let's put the ttest results into the same format as our xarray datasets\n",
    "ds_ttest = xr.full_like(ds_mean, 0.0) # copy dataset format from ds_mean and set data values to 0.\n",
    "ds_ttest.rename(name_dict={var:'p_value'}) # rename the variable to p_value\n",
    "ds_ttest['p_value'] = (['lat','lon'],ttest_pvalue<0.05) # Fill in the blank values with our ttest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00044794, 0.00044436, 0.00044608, ..., 0.00044305, 0.00043472,\n",
       "        0.00044657],\n",
       "       [0.0006349 , 0.00063315, 0.00064695, ..., 0.0005913 , 0.00060991,\n",
       "        0.00061167],\n",
       "       [0.00133728, 0.00142585, 0.00140628, ..., 0.0012091 , 0.00127   ,\n",
       "        0.00129372],\n",
       "       ...,\n",
       "       [0.16412996, 0.16855228, 0.16743845, ..., 0.14194397, 0.14966384,\n",
       "        0.15866436],\n",
       "       [0.2001084 , 0.20268068, 0.20492612, ..., 0.18832965, 0.19431596,\n",
       "        0.19735214],\n",
       "       [0.17840334, 0.17876235, 0.1792337 , ..., 0.17603959, 0.17656434,\n",
       "        0.17723068]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(var,exp,dates,project):\n",
    "    ds_mean, ds_std = stats(var, exp, dates, project)\n",
    "    ds_mean_2, ds_std_2 = stats(var, \"historical\", ['1960-01-01','1990-01-01'], \"CMIP\")\n",
    "\n",
    "    num_years = 90 # the t-test needs to know how long our sample is.\n",
    "\n",
    "    # ttest_sub returns a numpy array of P-values, where P is between 0 and 1. for 95% significance P is below 0.05\n",
    "    ttest_pvalue = ttest_sub(ds_mean[var],ds_std[var],num_years,ds_mean_2[var],ds_std_2[var],num_years)\n",
    "\n",
    "    return ttest_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def moderated_exacerbated_with_significance(moderated,exacerbated,ttest_pvalue):\n",
    "\n",
    "    sig_mod = 0\n",
    "    insig_mod = 0\n",
    "    sig_exac = 0\n",
    "    insig_exac = 0\n",
    "    dunno = 0\n",
    "\n",
    "    for i in range(0,len(ttest_pvalue[:,0])-1): #longitude\n",
    "        for j in range(0,len(ttest_pvalue[0,:])-1): #latitude\n",
    "            #print(ttest_pvalue[i,j])\n",
    "            if moderated[i,j]-exacerbated[i,j] > 0 and ttest_pvalue[i,j] < 0.05:\n",
    "                sig_mod = sig_mod + moderated[i,j]\n",
    "                insig_exac = insig_exac + exacerbated[i,j]\n",
    "            elif moderated[i,j]-exacerbated[i,j] > 0 and ttest_pvalue[i,j] >= 0.05:\n",
    "                insig_mod = insig_mod + moderated[i,j]\n",
    "                insig_exac = insig_exac + exacerbated[i,j]\n",
    "            elif moderated[i,j]-exacerbated[i,j] < 0 and ttest_pvalue[i,j] < 0.05:\n",
    "                sig_exac = sig_exac + exacerbated[i,j]\n",
    "                insig_mod = insig_mod + moderated[i,j]\n",
    "            elif moderated[i,j]-exacerbated[i,j] < 0 and ttest_pvalue[i,j] <= 0.05:\n",
    "                insig_exac = insig_exac + exacerbated[i,j]\n",
    "                insig_mod = insig_mod + moderated[i,j]\n",
    "\n",
    "    return sig_mod, insig_mod, sig_exac, insig_exac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare where climate change is significant vs insignificant\n",
    "#pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(var, metric):\n",
    "    control_mean=global_mean(var,'historical',['1960-01-01','1990-01-01'],'CMIP').values #1960-1990 historical data\n",
    "    geo_mean=global_mean(var,'G6sulfur',['2070-01-01','2100-01-01'],'GeoMIP').values  \n",
    "    solar_mean=global_mean(var,'G6solar',['2070-01-01','2100-01-01'],'GeoMIP').values\n",
    "    sulfur_mean=global_mean(var,'G6sulfur',['2070-01-01','2100-01-01'],'GeoMIP').values\n",
    "    warming_mean=global_mean(var,\"ssp585\",['2070-01-01','2100-01-01'],\"ScenarioMIP\").values\n",
    "    ds_mean, ds_std = stats(var,'G6solar',['2070-01-01','2100-01-01'],'GeoMIP')\n",
    "    ds_mean_2, ds_std_2 = stats(var, \"historical\", ['1960-01-01','1990-01-01'], \"CMIP\")\n",
    "    num_years = 90 # the t-test needs to know how long our sample is.\n",
    "    # ttest_sub returns a numpy array of P-values, where P is between 0 and 1. for 95% significance P is below 0.05\n",
    "    ttest_pvalue = ttest_sub(ds_mean[var],ds_std[var],num_years,ds_mean_2[var],ds_std_2[var],num_years) #calculates p value for each value in array\n",
    "    global_moderated, global_exacerbated, land_moderated, land_exacerbated = moderated_exacerbated(var)\n",
    "    \n",
    "    geo_anom = geo_mean - control_mean\n",
    "    sulfur_solar_anom = sulfur_mean - solar_mean\n",
    "    geo_warming_anom = geo_mean - warming_mean\n",
    "    warming_anom = warming_mean - control_mean\n",
    "\n",
    "    if metric == \"global_mean_anomaly_control\":\n",
    "        return geo_mean - control_mean\n",
    "    elif metric == \"global_mean_anomaly_solar\":\n",
    "        return sulfur_mean - solar_mean\n",
    "    elif metric == \"global_mean_anomaly_warming\":\n",
    "        return geo_mean - warming_mean\n",
    "    elif metric == \"moderated_exacerbated\":\n",
    "        if geo_anom < warming_anom:\n",
    "            return \"moderated\"\n",
    "        elif warming_anom < geo_anom:\n",
    "            return \"exacerbated\"\n",
    "        else:\n",
    "            return \"N/A\"\n",
    "    elif metric == \"global_sig_mod\":\n",
    "        sig_mod, insig_mod, sig_exac, insig_exac = moderated_exacerbated_with_significance(global_moderated,global_exacerbated,ttest_pvalue)\n",
    "        return sig_mod\n",
    "    elif metric == \"global_insig_mod\":\n",
    "        sig_mod, insig_mod, sig_exac, insig_exac = moderated_exacerbated_with_significance(global_moderated,global_exacerbated,ttest_pvalue)\n",
    "        return insig_mod\n",
    "    elif metric == \"global_sig_exac\":\n",
    "        sig_mod, insig_mod, sig_exac, insig_exac = moderated_exacerbated_with_significance(global_moderated,global_exacerbated,ttest_pvalue)\n",
    "        return sig_exac\n",
    "    elif metric == \"global_insig_exac\":\n",
    "        sig_mod, insig_mod, sig_exac, insig_exac = moderated_exacerbated_with_significance(global_moderated,global_exacerbated,ttest_pvalue)\n",
    "        return insig_exac\n",
    "    elif metric == \"land_sig_mod\":\n",
    "        sig_mod, insig_mod, sig_exac, insig_exac = moderated_exacerbated_with_significance(land_moderated,land_exacerbated,ttest_pvalue)\n",
    "        return sig_mod\n",
    "    elif metric == \"land_insig_mod\":\n",
    "        sig_mod, insig_mod, sig_exac, insig_exac = moderated_exacerbated_with_significance(land_moderated,land_exacerbated,ttest_pvalue)\n",
    "        return insig_mod\n",
    "    elif metric == \"land_sig_exac\":\n",
    "        sig_mod, insig_mod, sig_exac, insig_exac = moderated_exacerbated_with_significance(land_moderated,land_exacerbated,ttest_pvalue)\n",
    "        return sig_exac\n",
    "    elif metric == \"land_insig_exac\":\n",
    "        sig_mod, insig_mod, sig_exac, insig_exac = moderated_exacerbated_with_significance(land_moderated,land_exacerbated,ttest_pvalue)\n",
    "        return insig_exac\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate(\"tas\", \"global_sig_exac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.46733453360821"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate(\"tas\", \"global_sig_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate(\"tas\", \"global_insig_exac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_ens-mean_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_historical_ens-mean_gn_1960-01-01_1990-01-01 ANN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate(\"tas\", \"global_insig_mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
