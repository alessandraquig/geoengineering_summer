{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "\n",
    "from nc_processing import *\n",
    "from analysis import * \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data directory to search for files using lists\n",
    "ceda_dir='/badc/cmip6/data/CMIP6/{project}/{centre}/{model}/{exp}/{run}/{domain}/{var}/gn/latest/'\n",
    "# define the base of the filename for the output file(s) using lists, note this matches the file format in the data directory except for the date_4_file section and the missing .nc. \n",
    "out_base='{var}_{domain}_{model}_{exp}_{run}_gn_{time_range}' # all that's missing is a .nc but we can add that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='UKESM1-0-LL'\n",
    "centre='MOHC'\n",
    "\n",
    "var='tas' # near surface air temperature\n",
    "domain='Amon'\n",
    "\n",
    "exp='G6sulfur'\n",
    "project='GeoMIP'\n",
    "\n",
    "run='r1i1p1f2'\n",
    "\n",
    "# Let's fill in the blanks in our directory structure with those variables\n",
    "test_dir = ceda_dir.format(model=model, centre=centre, var=var, domain=domain, exp=exp, project=project, run=run)\n",
    "# os.listdir just performs a normal \"ls\" command on the linux system with the text specified within the parentheses.\n",
    "test_dir_files = os.listdir(test_dir)\n",
    "print(test_dir_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the file path to the second file in that directory (python counts from zero for array positions.)\n",
    "fpath = test_dir + test_dir_files[1]\n",
    "ds = xr.open_dataset(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds\n",
    "#Uncomment if you need to see what's in ds (saves screen space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = xr.open_dataset(test_dir + test_dir_files[0])\n",
    "ds2 = xr.open_dataset(test_dir + test_dir_files[1])\n",
    "\n",
    "# add these datasets together concatenating along the time dimension.\n",
    "ds_combined = xr.concat([ds1, ds2], 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'time' (time: 360)>\n",
       "array([cftime.Datetime360Day(2070, 1, 16, 0, 0, 0, 0, 2, 16),\n",
       "       cftime.Datetime360Day(2070, 2, 16, 0, 0, 0, 0, 4, 46),\n",
       "       cftime.Datetime360Day(2070, 3, 16, 0, 0, 0, 0, 6, 76), ...,\n",
       "       cftime.Datetime360Day(2099, 10, 16, 0, 0, 0, 0, 2, 286),\n",
       "       cftime.Datetime360Day(2099, 11, 16, 0, 0, 0, 0, 4, 316),\n",
       "       cftime.Datetime360Day(2099, 12, 16, 0, 0, 0, 0, 6, 346)], dtype=object)\n",
       "Coordinates:\n",
       "    height   float64 1.5\n",
       "  * time     (time) object 2070-01-16 00:00:00 ... 2099-12-16 00:00:00\n",
       "Attributes:\n",
       "    bounds:         time_bnds\n",
       "    axis:           T\n",
       "    long_name:      time\n",
       "    standard_name:  time"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choosing a time range\n",
    "ds_70_100 = ds_combined.sel(time=slice('2070-01-01','2100-01-01'))\n",
    "ds_70_100.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating global time mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the get_fixed() function to return the gridcell area and land fraction for the model we want.\n",
    "ds_area, ds_land = get_fixed('MOHC','UKESM1-0-LL','r1i1p1f2') \n",
    "# NOTE - to do this for another model, you'll need to look up the run number used in the piControl experiment which stores the fx variables.\n",
    "# search on CEDA archive for \"areacella\" and \"<MODEL NAME>\" and it should show you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'area_weight' (lat: 144, lon: 192)>\n",
       "array([[6.197184e-07, 6.197184e-07, 6.197184e-07, ..., 6.197184e-07,\n",
       "        6.197184e-07, 6.197184e-07],\n",
       "       [1.858865e-06, 1.858865e-06, 1.858865e-06, ..., 1.858865e-06,\n",
       "        1.858865e-06, 1.858865e-06],\n",
       "       [3.097128e-06, 3.097128e-06, 3.097128e-06, ..., 3.097128e-06,\n",
       "        3.097128e-06, 3.097128e-06],\n",
       "       ...,\n",
       "       [3.097128e-06, 3.097128e-06, 3.097128e-06, ..., 3.097128e-06,\n",
       "        3.097128e-06, 3.097128e-06],\n",
       "       [1.858865e-06, 1.858865e-06, 1.858865e-06, ..., 1.858865e-06,\n",
       "        1.858865e-06, 1.858865e-06],\n",
       "       [6.197184e-07, 6.197184e-07, 6.197184e-07, ..., 6.197184e-07,\n",
       "        6.197184e-07, 6.197184e-07]], dtype=float32)\n",
       "Coordinates:\n",
       "  * lat      (lat) float64 -89.38 -88.12 -86.88 -85.62 ... 86.88 88.12 89.38\n",
       "  * lon      (lon) float64 0.9375 2.812 4.688 6.562 ... 353.4 355.3 357.2 359.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what's in the area dataset \n",
    "ds_area['areacella']\n",
    "# Let's see what's in the land fraction dataset \n",
    "ds_land['sftlf']\n",
    "\n",
    "# Let's define a data array for the area weight of the gridcells\n",
    "da_weight = ds_area['areacella'] / ds_area['areacella'].sum()\n",
    "da_weight = da_weight.rename(new_name_or_name_dict='area_weight')\n",
    "da_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding global-mean temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n"
     ]
    }
   ],
   "source": [
    "data_dir='/home/users/quigley/Projects/geoengineering_summer' # !!!!!!!!!!!!! CHANGE THIS !!!!!!!!!!!!!!!!!!\n",
    "\n",
    "model='UKESM1-0-LL'\n",
    "centre='MOHC'\n",
    "\n",
    "var='tas'\n",
    "domain='Amon'\n",
    "\n",
    "exp='G6sulfur'\n",
    "project='GeoMIP'\n",
    "\n",
    "run='r1i1p1f2'\n",
    "\n",
    "grid='gn'\n",
    "\n",
    "season='ANN'\n",
    "dates=['2070-01-01','2100-01-01']\n",
    "\n",
    "time_files=1\n",
    "\n",
    "# load the arguments into a list then... \n",
    "args=[season,dates,data_dir,model,centre,var,domain,exp,project,run,grid,time_files]\n",
    "ds_mean, ds_std = get_seasonal_mean_std(*args) # ... unpack them into the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray ()>\n",
       "array(17.318323)\n",
       "Coordinates:\n",
       "    height   float64 ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply each temperature value with its corresponding fraction of total area, then sum to find the global mean.\n",
    "(ds_mean[var]*da_weight).sum() - 273.15 # convert from K to C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean(var,exp,dates,project):\n",
    "    data_dir='/home/users/quigley/Projects/geoengineering_summer' #Changed from Pete's directory\n",
    "    model='UKESM1-0-LL'\n",
    "    centre='MOHC'\n",
    "    domain='Amon'\n",
    "    run='r1i1p1f2'\n",
    "    grid='gn'\n",
    "    season='ANN'\n",
    "    time_files=1\n",
    "\n",
    "    # load the arguments into a list then... \n",
    "    args=[season,dates,data_dir,model,centre,var,domain,exp,project,run,grid,time_files]\n",
    "    ds_mean, ds_std = get_seasonal_mean_std(*args) # ... unpack them into the function.\n",
    "    \n",
    "    # multiply each temperature value with its corresponding fraction of total area, then sum to find the global mean.\n",
    "    return (ds_mean[var]*da_weight).sum() - 273.15 # convert from K to C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray ()>\n",
       "array(17.318323)\n",
       "Coordinates:\n",
       "    height   float64 ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_mean(dates=['2070-01-01','2100-01-01'],exp='G6sulfur',var='tas',project='GeoMIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray ()>\n",
       "array(17.318323)\n",
       "Coordinates:\n",
       "    height   float64 ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_mean(\"tas\",\"G6sulfur\",['2070-01-01','2100-01-01'],\"GeoMIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate_by_metric('tas', \"global_mean_anomaly_control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(var, metric):\n",
    "    #control_mean=global_mean(var,'historical',['1960-01-01','1990-01-01'],'CMIP') #is this modern or pre-industrial emissions?\n",
    "    \n",
    "    control_mean=0 #Just to test the function\n",
    "    \n",
    "    geo_mean=global_mean(var,'G6sulfur',['2070-01-01','2100-01-01'],'GeoMIP')  \n",
    "    solar_mean=global_mean(var,'G6solar',['2070-01-01','2100-01-01'],'GeoMIP')\n",
    "    sulfur_mean=global_mean(var,'G6sulfur',['2070-01-01','2100-01-01'],'GeoMIP')\n",
    "    warming_mean=global_mean(var,\"ssp585\",['2070-01-01','2100-01-01'],\"ScenarioMIP\")\n",
    "    \n",
    "    geo_anom = geo_mean - control_mean\n",
    "    sulfur_solar_anom = sulfur_mean - solar_mean\n",
    "    geo_warming_anom = geo_mean - warming_mean\n",
    "    warming_anom = warming_mean - control_mean\n",
    "    \n",
    "    if metric == \"global_mean_anomaly_control\":\n",
    "        return geo_mean - control_mean\n",
    "    elif metric == \"global_mean_anomaly_solar\":\n",
    "        return sulfur_mean - solar_mean\n",
    "    elif metric == \"global_mean_anomaly_warming\":\n",
    "        return geo_mean - warming_mean\n",
    "    elif metric == \"moderated_exacerbated\":\n",
    "        if geo_anom < warming_anom:\n",
    "            return \"moderated\"\n",
    "        elif warming_anom < geo_anom:\n",
    "            return \"exacerbated\"\n",
    "        else:\n",
    "            return \"N/A\"\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n"
     ]
    }
   ],
   "source": [
    "gm_anom = calculate(\"tas\",\"global_mean_anomaly_control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xarray.core.dataarray.DataArray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gm_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_anom = gm_anom.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(17.31832275)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6solar_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_G6sulfur_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n",
      "loading existing files tas_Amon_UKESM1-0-LL_ssp585_r1i1p1f2_gn_2070-01-01_2100-01-01 ANN\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5a71e2962278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(var,metric)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#calculate(\"tas\",\"global_mean_anomaly_control\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "var_list = ['tas']\n",
    "metric_list = ['global_mean_anomaly_control']\n",
    "empty_list = []\n",
    "output_array = np.array(empty_list)\n",
    "\n",
    "for var in var_list:\n",
    "    for metric in metric_list:\n",
    "        #print(var,metric)\n",
    "        output_array[var,metric] = calculate(var,metric).values\n",
    "        \n",
    "#calculate(\"tas\",\"global_mean_anomaly_control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(17.31832275)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['tas',\"pr\",\"huss\",\"tasmax\"]\n",
    "metric_list = ['global_mean_anomaly_control',\"global_mean_anomaly_solar\",\"global_mean_anomaly_warming\",\"moderated_exacerbated\"]\n",
    "\n",
    "dict_outer = {}\n",
    "for var in var_list:\n",
    "    dict_inner = {}\n",
    "    for metric in metric_list:\n",
    "        dict_inner[metric] = calculate(var,metric)    #CHANGE THIS!!!\n",
    "    dict_outer[var] = dict_inner\n",
    "    #end for metric\n",
    "#end for var\n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_outer)\n",
    "df.to_csv('metric_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputs = []\n",
    "for var in var_list:\n",
    "    for metric in metric_list:\n",
    "        #raw_outputs[var, metric] = calculate(var,metric)\n",
    "        type(calculate(var,metric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ec305bda6424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalue_for_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#value_for_table = dict_inner.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_bnds\n",
      "lat_bnds\n",
      "lon_bnds\n",
      "tas\n"
     ]
    }
   ],
   "source": [
    "for i in ds_mean:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_area = ds_area[\"areacella\"].values\n",
    "np_land = ds_land[\"sftlf\"].values\n",
    "np_land_area = np_land * np_area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
